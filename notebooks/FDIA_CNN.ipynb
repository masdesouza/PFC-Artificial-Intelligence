{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FDIA-CNN.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNJCdPRzT7FwgyBJjfCcPdU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/masdesouza/PFC-Artificial-Intelligence/blob/main/notebooks/FDIA_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEdmP_uPZV1w"
      },
      "source": [
        "#1. Import modules \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5ssDd5-O2Ti"
      },
      "source": [
        "import tensorflow.keras\n",
        "from tensorflow.keras.layers import Conv1D, BatchNormalization, Dropout, Dense, InputLayer, Flatten, MaxPool1D, Activation, GlobalAveragePooling1D\n",
        "from tensorflow.keras.activations import relu, softmax\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.models import Sequential,load_model"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Plf2dLocYwbd"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from sklearn import preprocessing"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suju70SwZsLZ"
      },
      "source": [
        "#2. Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1eEGePlyZsqz"
      },
      "source": [
        "# Setting seed for reproducibility\n",
        "np.random.seed(1234)  \n",
        "PYTHONHASHSEED = 0\n",
        "\n",
        "# define path to save model\n",
        "model_path = '../../Output/regression_model.h5'"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYNJwfobaZfI"
      },
      "source": [
        "##2.1 Import dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRN3KsygaMcc",
        "outputId": "bdda7ff5-7da9-4276-9069-9d69c6ec3c32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import os\n",
        "import pickle\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "os.chdir(\"/content/drive/MyDrive\")\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2NSzJ8ybHoQ",
        "outputId": "bd74ea41-f5b0-46c3-d6fa-bf84e9954a57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#https://www.nuscenes.org/nuimages#data-collection\n",
        "\n",
        "!mkdir -p /content/drive/MyDrive/PFC/nutonomy/data/sets/nuimages  # Make the directory to store the nuImages dataset in.\n",
        "\n",
        "!wget https://www.nuscenes.org/data/nuimages-v1.0-mini.tgz  # Download the nuImages mini split.\n",
        "\n",
        "!tar -xf nuimages-v1.0-mini.tgz -C /content/drive/MyDrive/PFC/nutonomy/data/sets/nuimages  # Uncompress the nuImages mini split.\n",
        "\n",
        "!pip install nuscenes-devkit &> /dev/null  # Install nuImages."
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-17 23:22:48--  https://www.nuscenes.org/data/nuimages-v1.0-mini.tgz\n",
            "Resolving www.nuscenes.org (www.nuscenes.org)... 54.230.226.63, 54.230.226.55, 54.230.226.125, ...\n",
            "Connecting to www.nuscenes.org (www.nuscenes.org)|54.230.226.63|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 117929607 (112M) [application/x-tar]\n",
            "Saving to: ‘nuimages-v1.0-mini.tgz.1’\n",
            "\n",
            "nuimages-v1.0-mini. 100%[===================>] 112.47M  43.1MB/s    in 2.6s    \n",
            "\n",
            "2021-08-17 23:22:51 (43.1 MB/s) - ‘nuimages-v1.0-mini.tgz.1’ saved [117929607/117929607]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUGG1M72a9Bb",
        "outputId": "7a696ee2-dd15-4801-c282-e72734ac5001",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%matplotlib inline\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "from nuimages import NuImages\n",
        "\n",
        "nuim = NuImages(dataroot='/content/drive/MyDrive/PFC/nutonomy/data/sets/nuimages', version='v1.0-mini', verbose=True, lazy=True)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n",
            "======\n",
            "Loading nuImages tables for version v1.0-mini...\n",
            "Done loading in 0.000 seconds (lazy=True).\n",
            "======\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKiwV0S4Ztlx"
      },
      "source": [
        "##################################\n",
        "# Data Ingestion\n",
        "##################################\n",
        "\n",
        "# read training data - It is the aircraft engine run-to-failure data.\n",
        "train_df = pd.read_csv('../../Dataset/train_FD002.txt', sep=\" \", header=None)\n",
        "train_df.drop(train_df.columns[[26, 27]], axis=1, inplace=True)\n",
        "train_df.columns = ['id', 'cycle', 'setting1', 'setting2', 'setting3', 's1', 's2', 's3',\n",
        "                     's4', 's5', 's6', 's7', 's8', 's9', 's10', 's11', 's12', 's13', 's14',\n",
        "                     's15', 's16', 's17', 's18', 's19', 's20', 's21']\n",
        "\n",
        "train_df = train_df.sort_values(['id','cycle'])\n",
        "\n",
        "# read test data - It is the aircraft engine operating data without failure events recorded.\n",
        "test_df = pd.read_csv('../../Dataset/test_FD002.txt', sep=\" \", header=None)\n",
        "test_df.drop(test_df.columns[[26, 27]], axis=1, inplace=True)\n",
        "test_df.columns = ['id', 'cycle', 'setting1', 'setting2', 'setting3', 's1', 's2', 's3',\n",
        "                     's4', 's5', 's6', 's7', 's8', 's9', 's10', 's11', 's12', 's13', 's14',\n",
        "                     's15', 's16', 's17', 's18', 's19', 's20', 's21']\n",
        "\n",
        "# read ground truth data - It contains the information of true remaining cycles for each engine in the testing data.\n",
        "truth_df = pd.read_csv('../../Dataset/RUL_FD002.txt', sep=\" \", header=None)\n",
        "truth_df.drop(truth_df.columns[[1]], axis=1, inplace=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOANeWdXaI9J"
      },
      "source": [
        "# Nova seção"
      ]
    }
  ]
}